{"version":3,"sources":["~lib/internal/allocator.ts","~lib/allocator/tlsf.ts","~lib/memory.ts","~lib/internal/memory.ts","assembly/index.ts","~lib/internal/typedarray.ts","~lib/internal/arraybuffer.ts"],"names":[],"mappings":"4QG8LE,AAAI,AAAC,KAAG,EACR,AAAU,EAAM,KAChB,AAAU,EAAO,GAAI,GAAG,KACxB,AAAI,EAAK,KAAG,EAEZ,AAAU,EAAO,GAAG,KACpB,AAAU,EAAO,GAAG,KACpB,AAAU,EAAO,GAAI,GAAG,KACxB,AAAU,EAAO,GAAI,GAAG,KACxB,AAAI,EAAK,KAAG,EACZ,AAAU,EAAO,GAAG,KACpB,AAAU,EAAO,GAAI,GAAG,KACxB,AAAI,EAAK,KAAG,EAWZ,AAPA,AADA,AAAe,EAAC,GAAO,KACvB,KAIA,AAAe,AAAgB,iBAI/B,AAAW,AANX,AADA,EAAK,GACA,KAMM,GAAW,GAAG,KACzB,AAAI,EAAK,KAAG,EACZ,AAAW,EAAO,GAAG,KACrB,AAAW,EAAO,GAAG,KACrB,AAAW,EAAO,GAAI,GAAI,KAC1B,AAAW,EAAO,GAAI,GAAG,KACzB,AAAI,EAAK,KAAI,EACb,AAAW,EAAO,GAAI,KACtB,AAAW,EAAO,GAAI,KACtB,AAAW,EAAO,GAAI,KACtB,AAAW,EAAO,GAAI,KACtB,AAAW,EAAO,GAAI,GAAI,KAC1B,AAAW,EAAO,GAAI,GAAI,KAC1B,AAAW,EAAO,GAAI,GAAI,KAC1B,AAAW,EAAO,GAAI,GAAI,KAI1B,AADA,AAAI,AAAK,AAAC,EAAO,GAAb,KACJ,KACA,EAAK,KAGL,AAAe,GAAW,AAAC,GAAY,QAChC,EAAK,KACV,AAAW,EAAM,KACjB,AAAW,EAAO,GAAG,KACrB,AAAW,EAAO,GAAI,KACtB,AAAW,EAAO,GAAI,KACtB,EAAK,KACL,EAAQ,YDrOR,AAAO,EAAM,EAAG,YCTN,AAAC,EAAM,KAAZ,KACK,SAAV,EAA2B,WAAT,SAClB,WAIF,AAAI,AAAC,EAAO,QACH,EAAK,KACV,AAAW,EAAW,AAAU,QAChC,AAAW,EAAQ,GAAG,AAAU,EAAO,SACvC,AAAW,EAAQ,GAAG,AAAU,EAAO,SACvC,AAAW,EAAO,GAAI,AAAU,EAAM,SACtC,EAAO,KAAI,EAAQ,KAAI,EAAK,SAE9B,AAAI,EAAI,KACN,AAAW,EAAU,AAAU,QAC/B,AAAW,EAAO,GAAG,AAAU,EAAM,SACrC,EAAQ,KAAG,EAAO,MAEpB,AAAI,EAAI,KACN,AAAW,EAAM,AAAU,QAC3B,EAAQ,KAAG,EAAO,MAEpB,AAAI,EAAI,KACN,AAAW,EAAM,AAAU,QAC3B,EAAQ,KAAG,EAAO,MAEpB,AAAI,EAAI,KACI,IADD,EACkB,MAAT,UAEpB,EAKF,AAAI,EAAK,KAAI,QACH,EAAO,aAGX,AAAI,AAAU,OACJ,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SAClB,EAAK,OACE,EAAK,KAEV,AAAW,EAAM,AAAU,AAD3B,AAAI,AAAU,EAAM,QACY,GAAf,EAAK,OAEtB,AAAW,EAAO,GAAG,AAAU,AAD/B,AAAI,AAAU,EAAM,QACgB,GAAf,EAAK,OAE1B,AAAW,EAAO,GAAG,AAAU,AAD/B,AAAI,AAAU,EAAM,QACgB,GAAf,EAAK,OAE1B,AAAW,EAAO,GAAI,AAAU,AADhC,AAAI,AAAU,EAAM,QACiB,GAAf,EAAK,OAC3B,EAAO,KAAI,EAAQ,KAAI,EAAK,SAE9B,GAGA,AAAI,AAAU,OACJ,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SAClB,EAAK,OACE,EAAK,KAEV,AAAW,EAAM,AAAU,AAD3B,AAAI,AAAU,EAAM,QACY,GAAf,EAAK,OAEtB,AAAW,EAAO,GAAG,AAAU,AAD/B,AAAI,AAAU,EAAM,QACgB,GAAf,EAAK,OAE1B,AAAW,EAAO,GAAG,AAAU,AAD/B,AAAI,AAAU,EAAM,QACgB,GAAf,EAAK,OAE1B,AAAW,EAAO,GAAI,AAAU,AADhC,AAAI,AAAU,EAAM,QACiB,GAAf,EAAK,OAC3B,EAAO,KAAI,EAAQ,KAAI,EAAK,SAE9B,GAGA,AAAI,AAAU,OACJ,SAAV,EAA2B,WAAT,SAClB,EAAK,OACE,EAAK,KAEV,AAAW,EAAM,AAAS,AAD1B,AAAI,AAAU,EAAM,QACW,GAAd,EAAK,OAEtB,AAAW,EAAO,GAAG,AAAS,AAD9B,AAAI,AAAU,EAAM,QACe,GAAd,EAAK,OAE1B,AAAW,EAAO,GAAG,AAAS,AAD9B,AAAI,AAAU,EAAM,QACe,GAAd,EAAK,OAE1B,AAAW,EAAO,GAAI,AAAS,AAD/B,AAAI,AAAU,EAAM,QACgB,GAAd,EAAK,OAC3B,EAAO,KAAI,EAAQ,KAAI,EAAK,WAQpC,AAAI,EAAI,KACI,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,UAEpB,AAAI,EAAI,KACI,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,UAEpB,AAAI,EAAI,KACI,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,UAEpB,AAAI,EAAI,KACI,SAAV,EAA2B,WAAT,SACR,SAAV,EAA2B,WAAT,UAEpB,AAAI,EAAI,KACI,IADD,EACkB,MAAT,gBAMpB,AAAI,EAAS,KAAK,EAClB,AAAI,EAAM,GAAK,UAAQ,EAAO,GAAK,MACjC,AAAO,EAAM,EAAK,IAClB,EAEF,AAAI,EAAO,KACT,AAAI,AAAC,EAAM,GAAM,AAAC,EAAO,QAChB,EAAO,KACZ,AAAI,AAAC,KAAG,EACR,AAAE,OACQ,SAAV,EAA2B,WAAT,eAEb,EAAK,KACV,AAAW,EAAM,AAAU,QAC3B,EAAQ,KACR,EAAQ,KACR,EAAQ,YAGL,IACK,SAAV,EAA2B,WAAT,SAClB,AAAE,YAGJ,AAAI,AAAC,EAAM,GAAM,AAAC,EAAO,QAChB,AAAC,EAAO,GAAK,KAClB,AAAI,AAAC,KAAG,EACR,AAAU,EAAO,AAAE,QAAG,AAAS,EAAM,eAEhC,EAAK,KAEV,AAAW,AADX,EAAK,KACM,GAAU,AAAU,EAAM,gBAGlC,IAAG,AACE,EAAO,AAAE,QAAG,AAAS,EAAM,iBDlKvC,AAAQ,EAAM,EAAK,SCqOrB,AAAI,EAAM,KAAW,MACd,EAAK,OAAK,AAAS,KAAO,AAAS,YACxC,OAAK,OAAM,WAEsC,AAA5C,IAAI,AAAc,KAAM,AAAc,OAAM,MDpO1B,AAAT,EAAI,EAAI,OD4JI,AAAa,GAAG,QArC1C,AAAO,oBACP,AAAW,EAA0B,EAAK,IAAG,QAsB7C,AAAO,oBACP,AAAO,oBACP,AACE,EAA0B,AAAC,KAAe,GAAa,IACvD,UAlFF,AAAO,wBAKP,AAHE,AACE,KAAuC,AAAC,gCAgV9C,AAAO,kBAEiB,AAAjB,EAAM,AAAO,OAhRlB,AAAO,oBACP,AAAO,oBAGS,AADd,EAA0B,AAAC,KAAe,GAAa,UAvBzD,AAAO,oBACyD,AAA/C,EAA0B,EAAK,aAuHhD,AAAO,AADP,AAAgB,0BAGhB,AAAO,AADP,AAAW,cACsB,6BAIjC,AAAI,QAEF,AAAK,AAAM,OADN,GAIL,AAAK,AAAM,AAAC,EAAQ,AADpB,AAAK,AAAW,eAEhB,QAKF,AAAW,OACX,AAFA,AAAW,SAED,EAAY,MACtB,AAAI,IAAM,EAAY,MAGtB,AAAI,AAAS,EAAa,EAAI,IAA1B,KACF,EAAa,EAAI,EAAI,IAGrB,AAAI,AAAC,KAEH,EAAc,EAAI,AADN,EAAc,IACC,AAAC,AAAC,EAAK,WAGlC,AAAI,AAAC,KAAO,OAAc,AAAC,AAAC,EAAK,kBAhNrC,AAAO,wBAGP,AADE,AAAY,EAA0B,6BA2PxC,AAAO,wBACP,AAAO,IAAc,kBACrB,AAAO,wBACP,AACE,EAA2B,GAC3B,WAtJF,AAAO,kBAEP,AAAO,AADP,AAAgB,0BAGhB,AACE,AAAQ,iBAAyC,6BAOnD,AAAI,AAHJ,AAAgB,AADhB,AAAmB,AAAO,oCAKxB,EAAY,IACZ,EAAa,AAAC,EAAa,AAAa,AAAC,cAEzC,AAAY,AADZ,AAAQ,YAMV,AAAI,OAGF,AAAO,AADP,AAAe,AADG,AAAO,WAAzB,6CAGA,EAAY,IACZ,EAAY,AAAC,EAAY,AAAa,AAAC,cACvC,AAAQ,IACR,AAAY,KAId,EAAa,QACb,AAAa,EAAO,IAIpB,AAAO,AADP,AAAO,cAC0B,6BAcjC,AAAW,EAVX,AAAI,QAEF,AAAK,AAAM,OADN,GAIL,AAAK,AAAM,AAAC,EAAQ,AADpB,AAAK,AAAW,eAEhB,QAI0B,MAC5B,EAAa,KACb,EAAa,KACb,AAAI,IAAM,EAAY,MACtB,EAAa,EAAI,EAAI,IAGrB,OAAc,AAAC,EAAK,OACpB,EAAc,EAAI,EAAc,IAAM,AAAC,EAAK,YAiI5C,AAAO,EAAS,kBAChB,AAAQ,AAAC,oBACT,AAAQ,AAAC,oBAIT,AAFA,UAGE,AAAO,EAAS,EAAU,mBAG1B,AAAI,KAAsB,KACxB,OACA,AAAW,SAGR,AACE,EAAS,uBAKlB,AAAI,AADJ,AAAW,EAAM,UACoC,AAC5C,IAMT,AADW,EACC,AAAkB,AAAC,KAAnB,AAFG,YAGf,EAAY,KACZ,EAAY,KAIZ,AADA,AAAW,AAAkB,EAAQ,aAErC,AAAe,IAEf,EAAY,IAEL,KAMT,AAAO,kBACW,AAAJ,SA/HZ,AAAO,SAA0B,6BAIjC,AAAI,QACF,AAAK,IACA,AAAM,MAIX,AAAK,AAAM,AAAC,EAAQ,AADpB,AAAK,AAAW,eAEhB,OAEA,AAAI,OAAoB,MACnB,AAAE,OAAS,MAMlB,AAFA,AAAY,EAAc,IAAM,EAAO,QAa9B,EAAa,EAAI,AAAS,OARjC,AADA,AAAY,KAAa,EAAO,AAAC,EAAK,SAK5B,AAAO,EADf,AAAK,AAAW,aAChB,qBACO,EAAa,EAAI,AAAS,OAJ1B,YA4BX,AAAO,AADP,AAAgB,0BAEhB,AAAO,SAA0B,6BACjC,AAAQ,AAAC,oBAET,EAAY,IAIZ,AAAI,AADJ,AAAgB,AAAC,KAAqB,UAEpC,EAAa,EAAO,AAAC,SAKrB,AAHA,AAAY,AACV,KAAwC,KAE7B,AAAC,WACd,EAAY,KAIZ,EAAa,QAEb,AADmB,AAAO,WAA1B,qBACA,YAGsC,AAAjC,WAuET,AAAI,AADJ,AAAW,OAKT,AAAI,AADJ,AAAkB,AAAM,AAFxB,eAE4E,KAD5E,AAAkB,SAEe,AAAY,EAAc,KAAe,SAAG,EAC7E,AAAO,AAAO,MACd,AAAe,IACf,EAAa,KACR,AAAgB,MAArB,EAAwB,OACtB,EAAc,EAAI,IACb,AAAc,MAAnB,EAAsB,OACpB,EAAa,EAAI,EAAI,IADa,AAAE,WAFF,AAAE,WAMxC,EAAe,AAAC,SAA8C,EAAiB,OAIjF,AAAI,WAAuB,EAM3B,AAAI,AADJ,AAAY,EAFZ,AAAO,AAAW,AAAC,6BASjB,AAAI,AADc,AAFlB,AAAkB,MAClB,AAAkB,AAAM,AAAC,AAAC,EAAO,UAAuB,eAEzB,KAAG,AAC5B,AAAY,IAAe,KAAG,GAKpC,EAAe,EAAsB,GAAI,AADxB,EAC6C,MACtD,AAAO,EAAY,SAA3B,sBAGF,AAAO,AAAC,QAAuB,kBACG,AAA3B,EAAS,EAAc,OC3ba,AAAkB,SDgc7D,AAAI,IAEF,AADA,AAAW,MAIT,AAAQ,AADR,AAAgB,AADhB,AAAY,AAAkB,8BAG9B,EAAa,QACb,EAAY,AAAkB,YCjcA,AAAc,WGR9C,AAAI,EAAc,AAAM,KAAoB,kBCwCkE,AAA3F,ADvCgB,KCuChB,ADvCJ,KCuCgC,AAAC,EAAgB,aD7C1B,AAA/B,KAAoB,OD1B3B,EAA8B,EAAI,KAC9B,AAAO,EAAE,IAAT,KADiC,WAG9B","sourceRoot":"assemblyscript:///","sourceContents":["/** Number of alignment bits. */\nexport const AL_BITS: u32 = 3;\n/** Number of possible alignment values. */\nexport const AL_SIZE: usize = 1 << <usize>AL_BITS;\n/** Mask to obtain just the alignment bits. */\nexport const AL_MASK: usize = AL_SIZE - 1;\n/** Maximum 32-bit allocation size. */\nexport const MAX_SIZE_32: usize = 1 << 30; // 1GB\n","/**\n * Two-Level Segregate Fit Memory Allocator.\n *\n * A general purpose dynamic memory allocator specifically designed to meet real-time requirements.\n * Always aligns to 8 bytes.\n *\n * @module std/assembly/allocator/tlsf\n *//***/\n\n// ╒══════════════ Block size interpretation (32-bit) ═════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┼─┴─┴─┴─┴─╫─┴─┴─┤\n// │ |                    FL                       │ SB = SL + AL  │ ◄─ usize\n// └───────────────────────────────────────────────┴─────────╨─────┘\n// FL: first level, SL: second level, AL: alignment, SB: small block\n\nimport {\n  AL_BITS,\n  AL_SIZE,\n  AL_MASK\n} from \"../internal/allocator\";\n\nconst SL_BITS: u32 = 5;\nconst SL_SIZE: usize = 1 << <usize>SL_BITS;\n\nconst SB_BITS: usize = <usize>(SL_BITS + AL_BITS);\nconst SB_SIZE: usize = 1 << <usize>SB_BITS;\n\nconst FL_BITS: u32 = (sizeof<usize>() == sizeof<u32>()\n  ? 30 // ^= up to 1GB per block\n  : 32 // ^= up to 4GB per block\n) - SB_BITS;\n\n// ╒════════════════ Block structure layout (32-bit) ══════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┼─┼─┤\n// │                          size                             │L│F│ ◄─┐ info\n// ╞═══════════════════════════════════════════════════════════╧═╧═╡   │      ┐\n// │                        if free: ◄ prev                        │ ◄─┤ usize\n// ├───────────────────────────────────────────────────────────────┤   │\n// │                        if free: next ►                        │ ◄─┤\n// ├───────────────────────────────────────────────────────────────┤   │\n// │                ... unused free space >= 0 ...                 │   │    = 0\n// ├ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ┤   │\n// │                        if free: jump ▲                        │ ◄─┘\n// └───────────────────────────────────────────────────────────────┘ MIN SIZE ┘\n// F: FREE, L: LEFT_FREE\n\n/** Tag indicating that this block is free. */\nconst FREE: usize = 1 << 0;\n/** Tag indicating that this block's left block is free. */\nconst LEFT_FREE: usize = 1 << 1;\n/** Mask to obtain all tags. */\nconst TAGS: usize = FREE | LEFT_FREE;\n\n/** Block structure. */\n@unmanaged\nclass Block {\n\n  /** Info field holding this block's size and tags. */\n  info: usize;\n\n  /** End offset of the {@link Block#info} field. User data starts here. */\n  static readonly INFO: usize = (sizeof<usize>() + AL_MASK) & ~AL_MASK;\n\n  /** Previous free block, if any. Only valid if free. */\n  prev: Block | null;\n  /** Next free block, if any. Only valid if free. */\n  next: Block | null;\n\n  /** Minimum size of a block, excluding {@link Block#info}. */\n  static readonly MIN_SIZE: usize = (3 * sizeof<usize>() + AL_MASK) & ~AL_MASK;// prev + next + jump\n\n  /** Maximum size of a used block, excluding {@link Block#info}. */\n  static readonly MAX_SIZE: usize = 1 << (FL_BITS + SB_BITS);\n\n  /** Gets this block's left (free) block in memory. */\n  get left(): Block {\n    assert(this.info & LEFT_FREE); // must be free to contain a jump\n    return assert(\n      load<Block>(changetype<usize>(this) - sizeof<usize>())\n    ); // can't be null\n  }\n\n  /** Gets this block's right block in memory. */\n  get right(): Block {\n    assert(this.info & ~TAGS); // can't skip beyond the tail block\n    return assert(\n      changetype<Block>(\n        changetype<usize>(this) + Block.INFO + (this.info & ~TAGS)\n      )\n    ); // can't be null\n  }\n}\n\n// ╒════════════════ Root structure layout (32-bit) ═══════════════╕\n//    3                   2                   1\n//  1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0  bits\n// ├─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┴─┤          ┐\n// │        0        |           flMap                            S│ ◄────┐\n// ╞═══════════════════════════════════════════════════════════════╡      │\n// │                           slMap[0] S                          │ ◄─┐  │\n// ├───────────────────────────────────────────────────────────────┤   │  │\n// │                           slMap[1]                            │ ◄─┤  │\n// ├───────────────────────────────────────────────────────────────┤  u32 │\n// │                              ...                              │ ◄─┤  │\n// ├───────────────────────────────────────────────────────────────┤   │  │\n// │                           slMap[22] P                         │ ◄─┘  │\n// ╞═══════════════════════════════════════════════════════════════╡    usize\n// │                            head[0]                            │ ◄────┤\n// ├───────────────────────────────────────────────────────────────┤      │\n// │                              ...                              │ ◄────┤\n// ├───────────────────────────────────────────────────────────────┤      │\n// │                           head[736]                           │ ◄────┤\n// ╞═══════════════════════════════════════════════════════════════╡      │\n// │                            tailRef                            │ ◄────┘\n// └───────────────────────────────────────────────────────────────┘   SIZE   ┘\n// S: Small blocks map, P: Possibly padded if 64-bit\n\nassert((1 << SL_BITS) <= 32); // second level must fit into 32 bits\n\n/** Root structure. */\n@unmanaged\nclass Root {\n\n  /** First level bitmap. */\n  flMap: usize = 0;\n\n  /** Start offset of second level maps. */\n  private static readonly SL_START: usize = sizeof<usize>();\n\n  // Using *one* SL map per *FL bit*\n\n  /** Gets the second level map for the specified first level. */\n  getSLMap(fl: usize): u32 {\n    assert(fl < FL_BITS); // fl out of range\n    return load<u32>(changetype<usize>(this) + fl * 4, Root.SL_START);\n  }\n\n  /** Sets the second level map for the specified first level. */\n  setSLMap(fl: usize, value: u32): void {\n    assert(fl < FL_BITS); // fl out of range\n    store<u32>(changetype<usize>(this) + fl * 4, value, Root.SL_START);\n  }\n\n  /** End offset of second level maps. */\n  private static readonly SL_END: usize = Root.SL_START + FL_BITS * 4;\n\n  // Using *number bits per SL* heads per *FL bit*\n\n  /** Start offset of FL/SL heads. */\n  private static readonly HL_START: usize = (Root.SL_END + AL_MASK) & ~AL_MASK;\n\n  /** Gets the head of the specified first and second level index. */\n  getHead(fl: usize, sl: u32): Block | null {\n    assert(fl < FL_BITS); // fl out of range\n    assert(sl < SL_SIZE); // sl out of range\n    return changetype<Block>(load<usize>(\n      changetype<usize>(this) + (fl * SL_SIZE + <usize>sl) * sizeof<usize>()\n    , Root.HL_START));\n  }\n\n  /** Sets the head of the specified first and second level index. */\n  setHead(fl: usize, sl: u32, value: Block | null): void {\n    assert(fl < FL_BITS); // fl out of range\n    assert(sl < SL_SIZE); // sl out of range\n    store<usize>(\n      changetype<usize>(this) + (fl * SL_SIZE + <usize>sl) * sizeof<usize>()\n    , changetype<usize>(value)\n    , Root.HL_START);\n  }\n\n  /** End offset of FL/SL heads. */\n  private static readonly HL_END: usize = (\n    Root.HL_START + FL_BITS * SL_SIZE * sizeof<usize>()\n  );\n\n  get tailRef(): usize { return load<usize>(0, Root.HL_END); }\n  set tailRef(value: usize) { store<usize>(0, value, Root.HL_END); }\n\n  /** Total size of the {@link Root} structure. */\n  static readonly SIZE: usize = Root.HL_END + sizeof<usize>();\n\n  /** Inserts a previously used block back into the free list. */\n  insert(block: Block): void {\n    // check as much as possible here to prevent invalid free blocks\n    assert(block); // cannot be null\n    var blockInfo = block.info;\n    assert(blockInfo & FREE); // must be free\n    var size: usize;\n    assert(\n      (size = block.info & ~TAGS) >= Block.MIN_SIZE && size < Block.MAX_SIZE\n    ); // must be valid, not necessary to compute yet if noAssert=true\n\n    var right: Block = assert(block.right); // can't be null\n    var rightInfo = right.info;\n\n    // merge with right block if also free\n    if (rightInfo & FREE) {\n      this.remove(right);\n      block.info = (blockInfo += Block.INFO + (rightInfo & ~TAGS));\n      right = block.right;\n      rightInfo = right.info;\n      // jump is set below\n    }\n\n    // merge with left block if also free\n    if (blockInfo & LEFT_FREE) {\n      let left: Block = assert(block.left); // can't be null\n      let leftInfo = left.info;\n      assert(leftInfo & FREE); // must be free according to tags\n      this.remove(left);\n      left.info = (leftInfo += Block.INFO + (blockInfo & ~TAGS));\n      block = left;\n      blockInfo = leftInfo;\n      // jump is set below\n    }\n\n    right.info = rightInfo | LEFT_FREE;\n    this.setJump(block, right);\n    // right is no longer used now, hence rightInfo is not synced\n\n    size = blockInfo & ~TAGS;\n    assert(size >= Block.MIN_SIZE && size < Block.MAX_SIZE); // must be valid\n\n    // mapping_insert\n    var fl: usize, sl: u32;\n    if (size < SB_SIZE) {\n      fl = 0;\n      sl = <u32>(size / AL_SIZE);\n    } else {\n      fl = fls<usize>(size);\n      sl = <u32>((size >> (fl - SL_BITS)) ^ (1 << SL_BITS));\n      fl -= SB_BITS - 1;\n    }\n\n    // perform insertion\n    var head = this.getHead(fl, sl);\n    block.prev = null;\n    block.next = head;\n    if (head) head.prev = block;\n    this.setHead(fl, sl, block);\n\n    // update first and second level maps\n    this.flMap |= (1 << fl);\n    this.setSLMap(fl, this.getSLMap(fl) | (1 << sl));\n  }\n\n  /**\n   * Removes a free block from FL/SL maps. Does not alter left/jump because it\n   * is likely that splitting is performed afterwards, invalidating any changes\n   * again.\n   */\n  private remove(block: Block): void {\n    var blockInfo = block.info;\n    assert(blockInfo & FREE); // must be free\n    var size = blockInfo & ~TAGS;\n    assert(size >= Block.MIN_SIZE && size < Block.MAX_SIZE); // must be valid\n\n    // mapping_insert\n    var fl: usize, sl: u32;\n    if (size < SB_SIZE) {\n      fl = 0;\n      sl = <u32>(size / AL_SIZE);\n    } else {\n      fl = fls<usize>(size);\n      sl = <u32>((size >> (fl - SL_BITS)) ^ (1 << SL_BITS));\n      fl -= SB_BITS - 1;\n    }\n\n    // link previous and next free block\n    var prev = block.prev;\n    var next = block.next;\n    if (prev) prev.next = next;\n    if (next) next.prev = prev;\n\n    // update head if we are removing it\n    if (block == this.getHead(fl, sl)) {\n      this.setHead(fl, sl, next);\n\n      // clear second level map if head is empty now\n      if (!next) {\n        let slMap = this.getSLMap(fl);\n        this.setSLMap(fl, slMap &= ~(1 << sl));\n\n        // clear first level map if second level is empty now\n        if (!slMap) this.flMap &= ~(1 << fl);\n      }\n    }\n  }\n\n  /** Searches for a free block of at least the specified size. */\n  search(size: usize): Block | null {\n    assert(size >= Block.MIN_SIZE && size < Block.MAX_SIZE);\n\n    // mapping_search\n    var fl: usize, sl: u32;\n    if (size < SB_SIZE) {\n      fl = 0;\n      sl = <u32>(size / AL_SIZE);\n    } else {\n      // (*) size += (1 << (fls<usize>(size) - SL_BITS)) - 1;\n      fl = fls<usize>(size);\n      sl = <u32>((size >> (fl - SL_BITS)) ^ (1 << SL_BITS));\n      fl -= SB_BITS - 1;\n      // (*) instead of rounding up, use next second level list for better fit\n      if (sl < SL_SIZE - 1) ++sl;\n      else ++fl, sl = 0;\n    }\n\n    // search second level\n    var slMap = this.getSLMap(fl) & (~0 << sl);\n    var head: Block | null;\n    if (!slMap) {\n      // search next larger first level\n      let flMap = this.flMap & (~0 << (fl + 1));\n      if (!flMap) {\n        head = null;\n      } else {\n        fl = ffs<usize>(flMap);\n        slMap = assert(this.getSLMap(fl)); // can't be zero if fl points here\n        head = this.getHead(fl, ffs<u32>(slMap));\n      }\n    } else {\n      head = this.getHead(fl, ffs<u32>(slMap));\n    }\n    return head;\n  }\n\n  /** Links a free left with its right block in memory. */\n  private setJump(left: Block, right: Block): void {\n    assert(left.info & FREE);       // must be free\n    assert(left.right == right);    // right block must match\n    assert(right.info & LEFT_FREE); // right block must be tagged as LEFT_FREE\n    store<Block>(\n      changetype<usize>(right) - sizeof<usize>()\n    , left); // last word in left block's (free) data region\n  }\n\n  /**\n   * Uses the specified free block, removing it from internal maps and\n   * splitting it if possible, and returns its data pointer.\n   */\n  use(block: Block, size: usize): usize {\n    var blockInfo = block.info;\n    assert(blockInfo & FREE); // must be free so we can use it\n    assert(size >= Block.MIN_SIZE && size < Block.MAX_SIZE); // must be valid\n    assert(!(size & AL_MASK)); // size must be aligned so the new block is\n\n    this.remove(block);\n\n    // split if the block can hold another MIN_SIZE block\n    var remaining = (blockInfo & ~TAGS) - size;\n    if (remaining >= Block.INFO + Block.MIN_SIZE) {\n      block.info = size | (blockInfo & LEFT_FREE); // also discards FREE\n\n      let spare = changetype<Block>(\n        changetype<usize>(block) + Block.INFO + size\n      );\n      spare.info = (remaining - Block.INFO) | FREE; // not LEFT_FREE\n      this.insert(spare); // also sets jump\n\n    // otherwise tag block as no longer FREE and right as no longer LEFT_FREE\n    } else {\n      block.info = blockInfo & ~FREE;\n      let right: Block = assert(block.right); // can't be null (tail)\n      right.info &= ~LEFT_FREE;\n    }\n\n    return changetype<usize>(block) + Block.INFO;\n  }\n\n  /** Adds more memory to the pool. */\n  addMemory(start: usize, end: usize): bool {\n    assert(start <= end);\n    assert(!(start & AL_MASK)); // must be aligned\n    assert(!(end & AL_MASK)); // must be aligned\n\n    var tailRef = this.tailRef;\n    var tailInfo: usize = 0;\n    if (tailRef) {\n      assert(start >= tailRef + sizeof<usize>()); // starts after tail\n\n      // merge with current tail if adjacent\n      if (start - Block.INFO == tailRef) {\n        start -= Block.INFO;\n        tailInfo = changetype<Block>(tailRef).info;\n      }\n\n    } else {\n      assert(start >= changetype<usize>(this) + Root.SIZE); // starts after root\n    }\n\n    // check if size is large enough for a free block and the tail block\n    var size = end - start;\n    if (size < Block.INFO + Block.MIN_SIZE + Block.INFO) {\n      return false;\n    }\n\n    // left size is total minus its own and the zero-length tail's header\n    var leftSize = size - 2 * Block.INFO;\n    var left = changetype<Block>(start);\n    left.info = leftSize | FREE | (tailInfo & LEFT_FREE);\n    left.prev = null;\n    left.next = null;\n\n    // tail is a zero-length used block\n    var tail = changetype<Block>(start + size - Block.INFO);\n    tail.info = 0 | LEFT_FREE;\n    this.tailRef = changetype<usize>(tail);\n\n    this.insert(left); // also merges with free left before tail / sets jump\n\n    return true;\n  }\n}\n\n/** Determines the first (LSB to MSB) set bit's index of a word. */\nfunction ffs<T>(word: T): T {\n  assert(word != 0); // word cannot be 0\n  return ctz<T>(word);  // differs from ffs only for 0\n}\n\n/** Determines the last (LSB to MSB) set bit's index of a word. */\nfunction fls<T>(word: T): T {\n  assert(word != 0); // word cannot be 0\n  const inv: T = (sizeof<T>() << 3) - 1;\n  return inv - clz<T>(word);\n}\n\n/** Reference to the initialized {@link Root} structure, once initialized. */\nvar ROOT: Root = changetype<Root>(0);\n\n// Memory allocator interface\n\n/** Allocates a chunk of memory. */\n@global export function __memory_allocate(size: usize): usize {\n\n  // initialize if necessary\n  var root = ROOT;\n  if (!root) {\n    let rootOffset = (HEAP_BASE + AL_MASK) & ~AL_MASK;\n    let pagesBefore = memory.size();\n    let pagesNeeded = <i32>((((rootOffset + Root.SIZE) + 0xffff) & ~0xffff) >>> 16);\n    if (pagesNeeded > pagesBefore && memory.grow(pagesNeeded - pagesBefore) < 0) unreachable();\n    ROOT = root = changetype<Root>(rootOffset);\n    root.tailRef = 0;\n    root.flMap = 0;\n    for (let fl: usize = 0; fl < FL_BITS; ++fl) {\n      root.setSLMap(fl, 0);\n      for (let sl: u32 = 0; sl < SL_SIZE; ++sl) {\n        root.setHead(fl, sl, null);\n      }\n    }\n    root.addMemory((rootOffset + Root.SIZE + AL_MASK) & ~AL_MASK, memory.size() << 16);\n  }\n\n  // search for a suitable block\n  if (size > Block.MAX_SIZE) unreachable();\n\n  // 32-bit MAX_SIZE is 1 << 30 and itself aligned, hence the following can't overflow MAX_SIZE\n  size = max<usize>((size + AL_MASK) & ~AL_MASK, Block.MIN_SIZE);\n\n  var block = root.search(size);\n  if (!block) {\n\n    // request more memory\n    let pagesBefore = memory.size();\n    let pagesNeeded = <i32>(((size + 0xffff) & ~0xffff) >>> 16);\n    let pagesWanted = max(pagesBefore, pagesNeeded); // double memory\n    if (memory.grow(pagesWanted) < 0) {\n      if (memory.grow(pagesNeeded) < 0) {\n        unreachable(); // out of memory\n      }\n    }\n    let pagesAfter = memory.size();\n    root.addMemory(<usize>pagesBefore << 16, <usize>pagesAfter << 16);\n    block = assert(root.search(size)); // must be found now\n  }\n\n  assert((block.info & ~TAGS) >= size);\n  return root.use(<Block>block, size);\n}\n\n/** Frees the chunk of memory at the specified address. */\n@global export function __memory_free(data: usize): void {\n  if (data) {\n    let root = ROOT;\n    if (root) {\n      let block = changetype<Block>(data - Block.INFO);\n      let blockInfo = block.info;\n      assert(!(blockInfo & FREE)); // must be used\n      block.info = blockInfo | FREE;\n      root.insert(changetype<Block>(data - Block.INFO));\n    }\n  }\n}\n\n@global export function __memory_reset(): void {\n  unreachable();\n}\n","import { memcmp, memmove, memset } from \"./internal/memory\";\n\n@builtin export declare const HEAP_BASE: usize; // tslint:disable-line\n\n/* tslint:disable */\n\nexport namespace memory {\n\n  @builtin export declare function size(): i32;\n\n  @builtin export declare function grow(pages: i32): i32;\n\n  @inline export function fill(dest: usize, c: u8, n: usize): void { // see: musl/src/string/memset\n    if (isDefined(__memory_fill)) { __memory_fill(dest, c, n); return; }\n    memset(dest, c, n);\n  }\n\n  @inline export function copy(dest: usize, src: usize, n: usize): void { // see: musl/src/string/memmove.c\n    if (isDefined(__memory_copy)) { __memory_copy(dest, src, n); return; }\n    memmove(dest, src, n);\n  }\n\n  @inline export function compare(vl: usize, vr: usize, n: usize): i32 { // see: musl/src/string/memcmp.c\n    if (isDefined(__memory_compare)) return __memory_compare(vl, vr, n);\n    return memcmp(vl, vr, n);\n  }\n\n  // Passive segments\n\n  // export function init(segmentIndex: u32, srcOffset: usize, dstOffset: usize, n: usize): void {\n  //   __memory_init(segmentIndex, srcOffset, dstOffset);\n  // }\n\n  // export function drop(segmentIndex: u32): void {\n  //   __memory_drop(segmentIndex);\n  // }\n\n  // Allocator\n\n  @inline export function allocate(size: usize): usize {\n    if (isDefined(__memory_allocate)) return __memory_allocate(size);\n    WARNING(\"Calling 'memory.allocate' requires a memory manager to be present.\");\n    return <usize>unreachable();\n  }\n\n  @inline export function free(ptr: usize): void {\n    if (isDefined(__memory_free)) { __memory_free(ptr); return; }\n    WARNING(\"Calling 'memory.free' requires a memory manager to be present.\");\n    unreachable();\n  }\n\n  @inline export function reset(): void {\n    if (isDefined(__memory_reset)) { __memory_reset(); return; }\n    unreachable();\n  }\n}\n","// this function will go away once `memory.copy` becomes an intrinsic\nexport function memcpy(dest: usize, src: usize, n: usize): void { // see: musl/src/string/memcpy.c\n  var w: u32, x: u32;\n\n  // copy 1 byte each until src is aligned to 4 bytes\n  while (n && (src & 3)) {\n    store<u8>(dest++, load<u8>(src++));\n    n--;\n  }\n\n  // if dst is aligned to 4 bytes as well, copy 4 bytes each\n  if ((dest & 3) == 0) {\n    while (n >= 16) {\n      store<u32>(dest     , load<u32>(src     ));\n      store<u32>(dest +  4, load<u32>(src +  4));\n      store<u32>(dest +  8, load<u32>(src +  8));\n      store<u32>(dest + 12, load<u32>(src + 12));\n      src += 16; dest += 16; n -= 16;\n    }\n    if (n & 8) {\n      store<u32>(dest    , load<u32>(src    ));\n      store<u32>(dest + 4, load<u32>(src + 4));\n      dest += 8; src += 8;\n    }\n    if (n & 4) {\n      store<u32>(dest, load<u32>(src));\n      dest += 4; src += 4;\n    }\n    if (n & 2) { // drop to 2 bytes each\n      store<u16>(dest, load<u16>(src));\n      dest += 2; src += 2;\n    }\n    if (n & 1) { // drop to 1 byte\n      store<u8>(dest++, load<u8>(src++));\n    }\n    return;\n  }\n\n  // if dst is not aligned to 4 bytes, use alternating shifts to copy 4 bytes each\n  // doing shifts if faster when copying enough bytes (here: 32 or more)\n  if (n >= 32) {\n    switch (dest & 3) {\n      // known to be != 0\n      case 1: {\n        w = load<u32>(src);\n        store<u8>(dest++, load<u8>(src++));\n        store<u8>(dest++, load<u8>(src++));\n        store<u8>(dest++, load<u8>(src++));\n        n -= 3;\n        while (n >= 17) {\n          x = load<u32>(src + 1);\n          store<u32>(dest, w >> 24 | x << 8);\n          w = load<u32>(src + 5);\n          store<u32>(dest + 4, x >> 24 | w << 8);\n          x = load<u32>(src + 9);\n          store<u32>(dest + 8, w >> 24 | x << 8);\n          w = load<u32>(src + 13);\n          store<u32>(dest + 12, x >> 24 | w << 8);\n          src += 16; dest += 16; n -= 16;\n        }\n        break;\n      }\n      case 2: {\n        w = load<u32>(src);\n        store<u8>(dest++, load<u8>(src++));\n        store<u8>(dest++, load<u8>(src++));\n        n -= 2;\n        while (n >= 18) {\n          x = load<u32>(src + 2);\n          store<u32>(dest, w >> 16 | x << 16);\n          w = load<u32>(src + 6);\n          store<u32>(dest + 4, x >> 16 | w << 16);\n          x = load<u32>(src + 10);\n          store<u32>(dest + 8, w >> 16 | x << 16);\n          w = load<u32>(src + 14);\n          store<u32>(dest + 12, x >> 16 | w << 16);\n          src += 16; dest += 16; n -= 16;\n        }\n        break;\n      }\n      case 3: {\n        w = load<u32>(src);\n        store<u8>(dest++, load<u8>(src++));\n        n -= 1;\n        while (n >= 19) {\n          x = load<u32>(src + 3);\n          store<u32>(dest, w >> 8 | x << 24);\n          w = load<u32>(src + 7);\n          store<u32>(dest + 4, x >> 8 | w << 24);\n          x = load<u32>(src + 11);\n          store<u32>(dest + 8, w >> 8 | x << 24);\n          w = load<u32>(src + 15);\n          store<u32>(dest + 12, x >> 8 | w << 24);\n          src += 16; dest += 16; n -= 16;\n        }\n        break;\n      }\n    }\n  }\n\n  // copy remaining bytes one by one\n  if (n & 16) {\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n  }\n  if (n & 8) {\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n  }\n  if (n & 4) {\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n  }\n  if (n & 2) {\n    store<u8>(dest++, load<u8>(src++));\n    store<u8>(dest++, load<u8>(src++));\n  }\n  if (n & 1) {\n    store<u8>(dest++, load<u8>(src++));\n  }\n}\n\n// this function will go away once `memory.copy` becomes an intrinsic\nexport function memmove(dest: usize, src: usize, n: usize): void { // see: musl/src/string/memmove.c\n  if (dest === src) return;\n  if (src + n <= dest || dest + n <= src) {\n    memcpy(dest, src, n);\n    return;\n  }\n  if (dest < src) {\n    if ((src & 7) == (dest & 7)) {\n      while (dest & 7) {\n        if (!n) return;\n        --n;\n        store<u8>(dest++, load<u8>(src++));\n      }\n      while (n >= 8) {\n        store<u64>(dest, load<u64>(src));\n        n    -= 8;\n        dest += 8;\n        src  += 8;\n      }\n    }\n    while (n) {\n      store<u8>(dest++, load<u8>(src++));\n      --n;\n    }\n  } else {\n    if ((src & 7) == (dest & 7)) {\n      while ((dest + n) & 7) {\n        if (!n) return;\n        store<u8>(dest + --n, load<u8>(src + n));\n      }\n      while (n >= 8) {\n        n -= 8;\n        store<u64>(dest + n, load<u64>(src + n));\n      }\n    }\n    while (n) {\n      store<u8>(dest + --n, load<u8>(src + n));\n    }\n  }\n}\n\n// this function will go away once `memory.fill` becomes an intrinsic\nexport function memset(dest: usize, c: u8, n: usize): void { // see: musl/src/string/memset\n\n  // fill head and tail with minimal branching\n  if (!n) return;\n  store<u8>(dest, c);\n  store<u8>(dest + n - 1, c);\n  if (n <= 2) return;\n\n  store<u8>(dest + 1, c);\n  store<u8>(dest + 2, c);\n  store<u8>(dest + n - 2, c);\n  store<u8>(dest + n - 3, c);\n  if (n <= 6) return;\n  store<u8>(dest + 3, c);\n  store<u8>(dest + n - 4, c);\n  if (n <= 8) return;\n\n  // advance pointer to align it at 4-byte boundary\n  var k: usize = -dest & 3;\n  dest += k;\n  n -= k;\n  n &= -4;\n\n  var c32: u32 = <u32>-1 / 255 * c;\n\n  // fill head/tail up to 28 bytes each in preparation\n  store<u32>(dest, c32);\n  store<u32>(dest + n - 4, c32);\n  if (n <= 8) return;\n  store<u32>(dest + 4, c32);\n  store<u32>(dest + 8, c32);\n  store<u32>(dest + n - 12, c32);\n  store<u32>(dest + n - 8, c32);\n  if (n <= 24) return;\n  store<u32>(dest + 12, c32);\n  store<u32>(dest + 16, c32);\n  store<u32>(dest + 20, c32);\n  store<u32>(dest + 24, c32);\n  store<u32>(dest + n - 28, c32);\n  store<u32>(dest + n - 24, c32);\n  store<u32>(dest + n - 20, c32);\n  store<u32>(dest + n - 16, c32);\n\n  // align to a multiple of 8\n  k = 24 + (dest & 4);\n  dest += k;\n  n -= k;\n\n  // copy 32 bytes each\n  var c64: u64 = <u64>c32 | (<u64>c32 << 32);\n  while (n >= 32) {\n    store<u64>(dest, c64);\n    store<u64>(dest + 8, c64);\n    store<u64>(dest + 16, c64);\n    store<u64>(dest + 24, c64);\n    n -= 32;\n    dest += 32;\n  }\n}\n\nexport function memcmp(vl: usize, vr: usize, n: usize): i32 { // see: musl/src/string/memcmp.c\n  if (vl == vr) return 0;\n  while (n != 0 && load<u8>(vl) == load<u8>(vr)) {\n    n--; vl++; vr++;\n  }\n  return n ? <i32>load<u8>(vl) - <i32>load<u8>(vr) : 0;\n}\n","// build to 'build/main.wasm'\nimport 'allocator/tlsf';\n\nexport { memory };\n\nexport function sum(a: Int32Array): i32 {\n    let rtn = 0;\n    for (let i = 0, l = a.length; i < l; i++) {\n        rtn += a[i];\n    }\n    return rtn;\n}\n","import {\n  HEADER_SIZE as AB_HEADER_SIZE,\n  MAX_BLENGTH as AB_MAX_BLENGTH,\n  allocateUnsafe,\n  LOAD,\n  STORE\n} from \"./arraybuffer\";\n\nimport {\n  SORT as SORT_IMPL\n} from \"./sort\";\n\n/** Typed array base class. Not a global object. */\nexport abstract class TypedArray<T> {\n  [key: number]: T; // compatibility only\n\n  readonly buffer: ArrayBuffer;\n  readonly byteOffset: i32;\n  readonly byteLength: i32;\n\n  constructor(length: i32) {\n    const MAX_LENGTH = <u32>AB_MAX_BLENGTH / sizeof<T>();\n    if (<u32>length > MAX_LENGTH) throw new RangeError(\"Invalid typed array length\");\n    var byteLength = length << alignof<T>();\n    var buffer = allocateUnsafe(byteLength);\n    memory.fill(changetype<usize>(buffer) + AB_HEADER_SIZE, 0, <usize>byteLength);\n    this.buffer = buffer;\n    this.byteOffset = 0;\n    this.byteLength = byteLength;\n  }\n\n  @inline\n  get length(): i32 {\n    return this.byteLength >>> alignof<T>();\n  }\n\n  @operator(\"[]\")\n  protected __get(index: i32): T {\n    if (<u32>index >= <u32>(this.byteLength >>> alignof<T>())) throw new Error(\"Index out of bounds\");\n    return LOAD<T>(this.buffer, index, this.byteOffset);\n  }\n\n  @inline @operator(\"{}\")\n  protected __unchecked_get(index: i32): T {\n    return LOAD<T>(this.buffer, index, this.byteOffset);\n  }\n\n  @operator(\"[]=\")\n  protected __set(index: i32, value: NATIVE<T>): void {\n    if (<u32>index >= <u32>(this.byteLength >>> alignof<T>())) throw new Error(\"Index out of bounds\");\n    STORE<T,NATIVE<T>>(this.buffer, index, value, this.byteOffset);\n  }\n\n  @inline @operator(\"{}=\")\n  protected __unchecked_set(index: i32, value: NATIVE<T>): void {\n    STORE<T,NATIVE<T>>(this.buffer, index, value, this.byteOffset);\n  }\n\n  // copyWithin(target: i32, start: i32, end: i32 = this.length): this\n}\n\n@inline\nexport function FILL<TArray extends TypedArray<T>, T>(\n  array: TArray,\n  value: NATIVE<T>,\n  start: i32,\n  end: i32\n): TArray {\n  var buffer = array.buffer;\n  var byteOffset = array.byteOffset;\n  var len = array.length;\n  start = start < 0 ? max(len + start, 0) : min(start, len);\n  end   = end   < 0 ? max(len + end,   0) : min(end,   len);\n  if (sizeof<T>() == 1) {\n    if (start < end) {\n      memory.fill(\n        changetype<usize>(buffer) + start + byteOffset + AB_HEADER_SIZE,\n        <u8>value,\n        <usize>(end - start)\n      );\n    }\n  } else {\n    for (; start < end; ++start) {\n      STORE<T,NATIVE<T>>(buffer, start, value, byteOffset);\n    }\n  }\n  return array;\n}\n\n@inline\nexport function SORT<TArray extends TypedArray<T>, T>(\n  array: TArray,\n  comparator: (a: T, b: T) => i32\n): TArray {\n  var byteOffset = array.byteOffset;\n  var length = array.length;\n  if (length <= 1) return array;\n  var buffer = array.buffer;\n  if (length == 2) {\n    let a = LOAD<T>(buffer, 1, byteOffset);\n    let b = LOAD<T>(buffer, 0, byteOffset);\n    if (comparator(a, b) < 0) {\n      STORE<T>(buffer, 1, b, byteOffset);\n      STORE<T>(buffer, 0, a, byteOffset);\n    }\n    return array;\n  }\n  SORT_IMPL<T>(buffer, byteOffset, length, comparator);\n  return array;\n}\n\n@inline\nexport function SUBARRAY<TArray extends TypedArray<T>, T>(\n  array: TArray,\n  begin: i32,\n  end: i32\n): TArray {\n  var length = <i32>array.length;\n  if (begin < 0) begin = max(length + begin, 0);\n  else begin = min(begin, length);\n  if (end < 0) end = max(length + end, begin);\n  else end = max(min(end, length), begin);\n  var slice = memory.allocate(offsetof<TArray>());\n  store<usize>(slice, array.buffer, offsetof<TArray>(\"buffer\"));\n  store<i32>(slice, <i32>array.byteOffset + (begin << alignof<T>()), offsetof<TArray>(\"byteOffset\"));\n  store<i32>(slice, (end - begin) << alignof<T>(), offsetof<TArray>(\"byteLength\"));\n  return changetype<TArray>(slice);\n}\n\n@inline\nexport function REDUCE<TArray extends TypedArray<T>, T, TRet>(\n  array: TArray,\n  callbackfn: (accumulator: TRet, value: T, index: i32, array: TArray) => TRet,\n  initialValue: TRet\n): TRet {\n  var index = 0;\n  var length = <i32>array.length;\n  while (index != length) {\n    initialValue = callbackfn(\n      initialValue,\n      unchecked(array[index]),\n      index,\n      array,\n    );\n    ++index;\n  }\n  return initialValue;\n}\n\n@inline\nexport function REDUCE_RIGHT<TArray extends TypedArray<T>, T, TRet>(\n  array: TArray,\n  callbackfn: (accumulator: TRet, value: T, index: i32, array: TArray) => TRet,\n  initialValue: TRet\n): TRet {\n  var index = <i32>array.length - 1;\n  var length = -1;\n  while (index != length) {\n    initialValue = callbackfn(\n      initialValue,\n      unchecked(array[index]),\n      index,\n      array,\n    );\n    --index;\n  }\n  return initialValue;\n}\n\n@inline\nexport function MAP<TArray extends TypedArray<T>, T>(\n  array: TArray,\n  callbackfn: (value: T, index: i32, self: TArray) => T,\n): TArray {\n  var length: i32 = array.length;\n  var result = instantiate<TArray>(length);\n  var i: i32 = 0;\n  while (i < length) {\n    unchecked(result[i] = callbackfn(array[i], i, <TArray>array));\n    ++i;\n  }\n  return result;\n}\n","import {\n  AL_MASK,\n  MAX_SIZE_32\n } from \"./allocator\";\n\n/** Size of an ArrayBuffer header. */\nexport const HEADER_SIZE: usize = (offsetof<ArrayBuffer>() + AL_MASK) & ~AL_MASK;\n/** Maximum byte length of an ArrayBuffer. */\nexport const MAX_BLENGTH: i32 = <i32>MAX_SIZE_32 - HEADER_SIZE;\n\nfunction computeSize(byteLength: i32): usize {\n  // round up to power of 2, with HEADER_SIZE=8:\n  // 0            -> 2^3  = 8\n  // 1..8         -> 2^4  = 16\n  // 9..24        -> 2^5  = 32\n  // ...\n  // MAX_LENGTH   -> 2^30 = 0x40000000 (MAX_SIZE_32)\n  return <usize>1 << <usize>(<u32>32 - clz<u32>(byteLength + HEADER_SIZE - 1));\n}\n\n// Low-level utility\n\nfunction __gc(ref: usize): void {}\n\nexport function allocateUnsafe(byteLength: i32): ArrayBuffer {\n  assert(<u32>byteLength <= <u32>MAX_BLENGTH);\n  var buffer: usize;\n  if (isManaged<ArrayBuffer>()) {\n    buffer = __gc_allocate(computeSize(byteLength), __gc); // tslint:disable-line\n  } else {\n    buffer = memory.allocate(computeSize(byteLength));\n  }\n  store<i32>(buffer, byteLength, offsetof<ArrayBuffer>(\"byteLength\"));\n  return changetype<ArrayBuffer>(buffer);\n}\n\nexport function reallocateUnsafe(buffer: ArrayBuffer, newByteLength: i32): ArrayBuffer {\n  var oldByteLength = buffer.byteLength;\n  if (newByteLength > oldByteLength) {\n    assert(newByteLength <= MAX_BLENGTH);\n    if (newByteLength <= <i32>(computeSize(oldByteLength) - HEADER_SIZE)) { // fast path: zero out additional space\n      store<i32>(changetype<usize>(buffer), newByteLength, offsetof<ArrayBuffer>(\"byteLength\"));\n    } else { // slow path: copy to new buffer\n      let newBuffer = allocateUnsafe(newByteLength);\n      memory.copy(\n        changetype<usize>(newBuffer) + HEADER_SIZE,\n        changetype<usize>(buffer) + HEADER_SIZE,\n        <usize>oldByteLength\n      );\n      if (!isManaged<ArrayBuffer>()) {\n        memory.free(changetype<usize>(buffer));\n      }\n      buffer = newBuffer;\n    }\n    memory.fill(\n      changetype<usize>(buffer) + HEADER_SIZE + <usize>oldByteLength,\n      0,\n      <usize>(newByteLength - oldByteLength)\n    );\n  } else if (newByteLength < oldByteLength) { // fast path: override size\n    // TBD: worth to copy and release if size is significantly less than before?\n    assert(newByteLength >= 0);\n    store<i32>(changetype<usize>(buffer), newByteLength, offsetof<ArrayBuffer>(\"byteLength\"));\n  }\n  return buffer;\n}\n\n// The helpers below use two different types in order to emit loads and stores that load respectively\n// store one type to/from memory while returning/taking the desired output/input type. This allows to\n// emit instructions like\n//\n// * `i32.load8` ^= `<i32>load<i8>(...)` that reads an i8 but returns an i32, or\n// * `i64.load32_s` ^= `<i64>load<i32>(...)`) that reads a 32-bit as a 64-bit integer\n//\n// without having to emit an additional instruction for conversion purposes. The second parameter\n// can be omitted for references and other loads and stores that simply return the exact type.\n\n@inline export function LOAD<T,TOut = T>(buffer: ArrayBuffer, index: i32, byteOffset: i32 = 0): TOut {\n  return <TOut>load<T>(changetype<usize>(buffer) + (<usize>index << alignof<T>()) + <usize>byteOffset, HEADER_SIZE);\n}\n\n@inline export function STORE<T,TIn = T>(buffer: ArrayBuffer, index: i32, value: TIn, byteOffset: i32 = 0): void {\n  store<T>(changetype<usize>(buffer) + (<usize>index << alignof<T>()) + <usize>byteOffset, value, HEADER_SIZE);\n}\n"]}